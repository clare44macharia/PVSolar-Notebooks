{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import SGD\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "import keras.utils\n",
    "import keras.layers\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather = pd.read_csv(\"weather-daily.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Cloud coverage</th>\n",
       "      <th>Visibility</th>\n",
       "      <th>Temperature</th>\n",
       "      <th>Dew point</th>\n",
       "      <th>Relative humidity</th>\n",
       "      <th>Wind speed</th>\n",
       "      <th>Station pressure</th>\n",
       "      <th>Altimeter</th>\n",
       "      <th>Solar energy</th>\n",
       "      <th>(Inverters)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01-02-16</td>\n",
       "      <td>0.103750</td>\n",
       "      <td>9.447917</td>\n",
       "      <td>3.113750</td>\n",
       "      <td>0.321667</td>\n",
       "      <td>79.454583</td>\n",
       "      <td>4.694583</td>\n",
       "      <td>29.228750</td>\n",
       "      <td>30.019583</td>\n",
       "      <td>20256</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>02-02-16</td>\n",
       "      <td>0.798333</td>\n",
       "      <td>3.941250</td>\n",
       "      <td>6.992500</td>\n",
       "      <td>6.215417</td>\n",
       "      <td>93.597500</td>\n",
       "      <td>13.290833</td>\n",
       "      <td>28.911667</td>\n",
       "      <td>29.697917</td>\n",
       "      <td>1761</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>03-02-16</td>\n",
       "      <td>0.864583</td>\n",
       "      <td>8.699583</td>\n",
       "      <td>1.615000</td>\n",
       "      <td>0.022917</td>\n",
       "      <td>85.001667</td>\n",
       "      <td>16.726250</td>\n",
       "      <td>29.026667</td>\n",
       "      <td>29.814583</td>\n",
       "      <td>2775</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>04-02-16</td>\n",
       "      <td>0.372917</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>-2.472500</td>\n",
       "      <td>-5.886250</td>\n",
       "      <td>74.522500</td>\n",
       "      <td>9.455417</td>\n",
       "      <td>29.455000</td>\n",
       "      <td>30.254583</td>\n",
       "      <td>28695</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>05-02-16</td>\n",
       "      <td>0.515417</td>\n",
       "      <td>9.206667</td>\n",
       "      <td>-2.002917</td>\n",
       "      <td>-4.152083</td>\n",
       "      <td>82.027500</td>\n",
       "      <td>5.920000</td>\n",
       "      <td>29.550833</td>\n",
       "      <td>30.351250</td>\n",
       "      <td>9517</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Date  Cloud coverage  Visibility  Temperature  Dew point  \\\n",
       "0  01-02-16        0.103750    9.447917     3.113750   0.321667   \n",
       "1  02-02-16        0.798333    3.941250     6.992500   6.215417   \n",
       "2  03-02-16        0.864583    8.699583     1.615000   0.022917   \n",
       "3  04-02-16        0.372917   10.000000    -2.472500  -5.886250   \n",
       "4  05-02-16        0.515417    9.206667    -2.002917  -4.152083   \n",
       "\n",
       "   Relative humidity  Wind speed  Station pressure  Altimeter  Solar energy  \\\n",
       "0          79.454583    4.694583         29.228750  30.019583         20256   \n",
       "1          93.597500   13.290833         28.911667  29.697917          1761   \n",
       "2          85.001667   16.726250         29.026667  29.814583          2775   \n",
       "3          74.522500    9.455417         29.455000  30.254583         28695   \n",
       "4          82.027500    5.920000         29.550833  30.351250          9517   \n",
       "\n",
       "   (Inverters)  \n",
       "0          NaN  \n",
       "1          NaN  \n",
       "2          NaN  \n",
       "3          NaN  \n",
       "4          NaN  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(637, 11)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(weather, columns = ['Date', 'Cloud coverage', 'Visibility', 'Temperature', 'Dew point',\n",
    "       'Relative humidity', 'Wind speed', 'Station pressure', 'Altimeter',\n",
    "       'Solar energy', '(Inverters)']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#seperating day, month and year\n",
    "df['Day'] = pd.DatetimeIndex(df['Date']).day\n",
    "df['Month'] = pd.DatetimeIndex(df['Date']).month\n",
    "df['Year'] = pd.DatetimeIndex(df['Date']).year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(637, 14)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Date', 'Cloud coverage', 'Visibility', 'Temperature', 'Dew point',\n",
       "       'Relative humidity', 'Wind speed', 'Station pressure', 'Altimeter',\n",
       "       'Solar energy', '(Inverters)', 'Day', 'Month', 'Year'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df.iloc[:, 0:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.drop([\"(Inverters)\",\"Date\"], axis = 1, inplace = True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(637, 12)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = (['Cloud coverage', 'Visibility', 'Temperature', 'Dew point',\n",
    "       'Relative humidity', 'Wind speed', 'Station pressure', 'Altimeter',\n",
    "       'Day', 'Month', 'Year','Solar energy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = pd.DataFrame(X, columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(637, 12)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train and test data\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.33, random_state=42)\n",
    "#train_test_split(X, y, test_size=0.33, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Cloud coverage', 'Visibility', 'Temperature', 'Dew point',\n",
       "       'Relative humidity', 'Wind speed', 'Station pressure', 'Altimeter',\n",
       "       'Solar energy', 'Day', 'Month', 'Year'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For a mean squared error regression problem\n",
    "#model.compile(optimizer='rmsprop',\n",
    "#             loss='mse')\n",
    "X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(426, 12)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(426, 12)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = tf.ConfigProto(\n",
    "    device_count={'GPU': 1},\n",
    "    intra_op_parallelism_threads=1,\n",
    "    allow_soft_placement=True\n",
    ")\n",
    "\n",
    "config.gpu_options.allow_growth = True\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.6\n",
    "\n",
    "session = tf.Session(config=config)\n",
    "\n",
    "keras.backend.set_session(session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 426 samples, validate on 211 samples\n",
      "Epoch 1/150\n",
      "426/426 [==============================] - 2s 4ms/step - loss: 60021.2332 - acc: 0.5282 - val_loss: 56048.0291 - val_acc: 0.9810\n",
      "Epoch 2/150\n",
      "426/426 [==============================] - 0s 410us/step - loss: 58898.2929 - acc: 0.9648 - val_loss: 55491.0918 - val_acc: 0.9810\n",
      "Epoch 3/150\n",
      "426/426 [==============================] - 0s 383us/step - loss: 58328.6269 - acc: 0.9648 - val_loss: 54967.9532 - val_acc: 0.9810\n",
      "Epoch 4/150\n",
      "426/426 [==============================] - 0s 435us/step - loss: 57775.8310 - acc: 0.9648 - val_loss: 54446.9912 - val_acc: 0.9810\n",
      "Epoch 5/150\n",
      "426/426 [==============================] - 0s 352us/step - loss: 57222.1497 - acc: 0.9648 - val_loss: 53928.2761 - val_acc: 0.9810\n",
      "Epoch 6/150\n",
      "426/426 [==============================] - 0s 399us/step - loss: 56678.6878 - acc: 0.9648 - val_loss: 53420.6548 - val_acc: 0.9810\n",
      "Epoch 7/150\n",
      "426/426 [==============================] - 0s 422us/step - loss: 56136.2573 - acc: 0.9648 - val_loss: 52910.4983 - val_acc: 0.9810\n",
      "Epoch 8/150\n",
      "426/426 [==============================] - 0s 447us/step - loss: 55594.8699 - acc: 0.9648 - val_loss: 52397.9427 - val_acc: 0.9810\n",
      "Epoch 9/150\n",
      "426/426 [==============================] - 0s 389us/step - loss: 55054.9947 - acc: 0.9648 - val_loss: 51891.5799 - val_acc: 0.9810\n",
      "Epoch 10/150\n",
      "426/426 [==============================] - 0s 455us/step - loss: 54516.1566 - acc: 0.9648 - val_loss: 51379.8595 - val_acc: 0.9810\n",
      "Epoch 11/150\n",
      "426/426 [==============================] - 0s 402us/step - loss: 53977.6187 - acc: 0.9648 - val_loss: 50879.7810 - val_acc: 0.9810\n",
      "Epoch 12/150\n",
      "426/426 [==============================] - 0s 310us/step - loss: 53443.2347 - acc: 0.9648 - val_loss: 50366.4134 - val_acc: 0.9810\n",
      "Epoch 13/150\n",
      "426/426 [==============================] - 0s 405us/step - loss: 52905.0732 - acc: 0.9648 - val_loss: 49873.4958 - val_acc: 0.9810\n",
      "Epoch 14/150\n",
      "426/426 [==============================] - 0s 419us/step - loss: 52375.0259 - acc: 0.9648 - val_loss: 49367.6710 - val_acc: 0.9810\n",
      "Epoch 15/150\n",
      "426/426 [==============================] - 0s 333us/step - loss: 51850.8106 - acc: 0.9648 - val_loss: 48884.1302 - val_acc: 0.9810\n",
      "Epoch 16/150\n",
      "426/426 [==============================] - 0s 274us/step - loss: 51329.7534 - acc: 0.9648 - val_loss: 48375.8792 - val_acc: 0.9810\n",
      "Epoch 17/150\n",
      "426/426 [==============================] - 0s 360us/step - loss: 50792.8856 - acc: 0.9648 - val_loss: 47886.9284 - val_acc: 0.9810\n",
      "Epoch 18/150\n",
      "426/426 [==============================] - 0s 330us/step - loss: 50273.5446 - acc: 0.9648 - val_loss: 47393.6444 - val_acc: 0.9810\n",
      "Epoch 19/150\n",
      "426/426 [==============================] - 0s 315us/step - loss: 49750.7797 - acc: 0.9648 - val_loss: 46902.4166 - val_acc: 0.9810\n",
      "Epoch 20/150\n",
      "426/426 [==============================] - 0s 256us/step - loss: 49230.8621 - acc: 0.9648 - val_loss: 46407.0126 - val_acc: 0.9810\n",
      "Epoch 21/150\n",
      "426/426 [==============================] - 0s 294us/step - loss: 48711.8732 - acc: 0.9648 - val_loss: 45928.2720 - val_acc: 0.9810\n",
      "Epoch 22/150\n",
      "426/426 [==============================] - 0s 265us/step - loss: 48199.0644 - acc: 0.9648 - val_loss: 45442.3307 - val_acc: 0.9810\n",
      "Epoch 23/150\n",
      "426/426 [==============================] - 0s 402us/step - loss: 47687.3452 - acc: 0.9648 - val_loss: 44963.6456 - val_acc: 0.9810\n",
      "Epoch 24/150\n",
      "426/426 [==============================] - 0s 455us/step - loss: 47175.7788 - acc: 0.9648 - val_loss: 44481.0193 - val_acc: 0.9810\n",
      "Epoch 25/150\n",
      "426/426 [==============================] - 0s 317us/step - loss: 46670.1013 - acc: 0.9648 - val_loss: 44005.3034 - val_acc: 0.9810\n",
      "Epoch 26/150\n",
      "426/426 [==============================] - 0s 320us/step - loss: 46159.8404 - acc: 0.9648 - val_loss: 43524.4664 - val_acc: 0.9810\n",
      "Epoch 27/150\n",
      "426/426 [==============================] - 0s 292us/step - loss: 45654.7454 - acc: 0.9648 - val_loss: 43060.9475 - val_acc: 0.9810\n",
      "Epoch 28/150\n",
      "426/426 [==============================] - 0s 373us/step - loss: 45160.0235 - acc: 0.9648 - val_loss: 42585.5775 - val_acc: 0.9810\n",
      "Epoch 29/150\n",
      "426/426 [==============================] - 0s 453us/step - loss: 44657.5918 - acc: 0.9648 - val_loss: 42118.2408 - val_acc: 0.9810\n",
      "Epoch 30/150\n",
      "426/426 [==============================] - 0s 398us/step - loss: 44162.3660 - acc: 0.9648 - val_loss: 41651.7757 - val_acc: 0.9810\n",
      "Epoch 31/150\n",
      "426/426 [==============================] - 0s 346us/step - loss: 43670.1074 - acc: 0.9648 - val_loss: 41185.7256 - val_acc: 0.9810\n",
      "Epoch 32/150\n",
      "426/426 [==============================] - 0s 342us/step - loss: 43178.1134 - acc: 0.9648 - val_loss: 40736.8121 - val_acc: 0.9810\n",
      "Epoch 33/150\n",
      "426/426 [==============================] - 0s 417us/step - loss: 42696.6289 - acc: 0.9648 - val_loss: 40277.6754 - val_acc: 0.9810\n",
      "Epoch 34/150\n",
      "426/426 [==============================] - 0s 320us/step - loss: 42208.7663 - acc: 0.9648 - val_loss: 39816.3201 - val_acc: 0.9810\n",
      "Epoch 35/150\n",
      "426/426 [==============================] - 0s 382us/step - loss: 41724.3943 - acc: 0.9648 - val_loss: 39364.2634 - val_acc: 0.9810\n",
      "Epoch 36/150\n",
      "426/426 [==============================] - 0s 404us/step - loss: 41245.3484 - acc: 0.9648 - val_loss: 38922.5902 - val_acc: 0.9810\n",
      "Epoch 37/150\n",
      "426/426 [==============================] - 0s 407us/step - loss: 40775.9996 - acc: 0.9648 - val_loss: 38465.6687 - val_acc: 0.9810\n",
      "Epoch 38/150\n",
      "426/426 [==============================] - 0s 324us/step - loss: 40295.7164 - acc: 0.9648 - val_loss: 38021.7375 - val_acc: 0.9810\n",
      "Epoch 39/150\n",
      "426/426 [==============================] - 0s 336us/step - loss: 39825.2767 - acc: 0.9648 - val_loss: 37582.1127 - val_acc: 0.9810\n",
      "Epoch 40/150\n",
      "426/426 [==============================] - 0s 348us/step - loss: 39359.8030 - acc: 0.9648 - val_loss: 37143.8267 - val_acc: 0.9810\n",
      "Epoch 41/150\n",
      "426/426 [==============================] - 0s 422us/step - loss: 38894.3167 - acc: 0.9648 - val_loss: 36708.9359 - val_acc: 0.9810\n",
      "Epoch 42/150\n",
      "426/426 [==============================] - 0s 344us/step - loss: 38432.8493 - acc: 0.9648 - val_loss: 36270.7036 - val_acc: 0.9810\n",
      "Epoch 43/150\n",
      "426/426 [==============================] - 0s 304us/step - loss: 37973.3839 - acc: 0.9648 - val_loss: 35853.4740 - val_acc: 0.9810\n",
      "Epoch 44/150\n",
      "426/426 [==============================] - 0s 372us/step - loss: 37525.1002 - acc: 0.9648 - val_loss: 35426.9271 - val_acc: 0.9810\n",
      "Epoch 45/150\n",
      "426/426 [==============================] - 0s 382us/step - loss: 37073.0461 - acc: 0.9648 - val_loss: 34997.6904 - val_acc: 0.9810\n",
      "Epoch 46/150\n",
      "426/426 [==============================] - 0s 391us/step - loss: 36618.9416 - acc: 0.9648 - val_loss: 34573.7751 - val_acc: 0.9810\n",
      "Epoch 47/150\n",
      "426/426 [==============================] - 0s 348us/step - loss: 36175.5268 - acc: 0.9648 - val_loss: 34162.0417 - val_acc: 0.9810\n",
      "Epoch 48/150\n",
      "426/426 [==============================] - 0s 460us/step - loss: 35734.5571 - acc: 0.9648 - val_loss: 33743.0084 - val_acc: 0.9810\n",
      "Epoch 49/150\n",
      "426/426 [==============================] - 0s 331us/step - loss: 35297.2684 - acc: 0.9648 - val_loss: 33340.6531 - val_acc: 0.9810\n",
      "Epoch 50/150\n",
      "426/426 [==============================] - 0s 244us/step - loss: 34866.1571 - acc: 0.9648 - val_loss: 32934.2075 - val_acc: 0.9810\n",
      "Epoch 51/150\n",
      "426/426 [==============================] - 0s 304us/step - loss: 34433.4576 - acc: 0.9648 - val_loss: 32526.7010 - val_acc: 0.9810\n",
      "Epoch 52/150\n",
      "426/426 [==============================] - 0s 304us/step - loss: 34004.4871 - acc: 0.9648 - val_loss: 32123.9486 - val_acc: 0.9810\n",
      "Epoch 53/150\n",
      "426/426 [==============================] - 0s 330us/step - loss: 33579.8364 - acc: 0.9648 - val_loss: 31725.2941 - val_acc: 0.9810\n",
      "Epoch 54/150\n",
      "426/426 [==============================] - 0s 333us/step - loss: 33155.6348 - acc: 0.9648 - val_loss: 31328.8942 - val_acc: 0.9810\n",
      "Epoch 55/150\n",
      "426/426 [==============================] - 0s 431us/step - loss: 32739.4366 - acc: 0.9648 - val_loss: 30943.8140 - val_acc: 0.9810\n",
      "Epoch 56/150\n",
      "426/426 [==============================] - 0s 447us/step - loss: 32329.3043 - acc: 0.9648 - val_loss: 30556.8111 - val_acc: 0.9810\n",
      "Epoch 57/150\n",
      "426/426 [==============================] - 0s 447us/step - loss: 31918.1442 - acc: 0.9648 - val_loss: 30167.8804 - val_acc: 0.9810\n",
      "Epoch 58/150\n",
      "426/426 [==============================] - 0s 347us/step - loss: 31508.5473 - acc: 0.9648 - val_loss: 29787.1371 - val_acc: 0.9810\n",
      "Epoch 59/150\n",
      "426/426 [==============================] - 0s 500us/step - loss: 31107.6313 - acc: 0.9648 - val_loss: 29411.8056 - val_acc: 0.9810\n",
      "Epoch 60/150\n",
      "426/426 [==============================] - 0s 285us/step - loss: 30713.5623 - acc: 0.9648 - val_loss: 29047.7071 - val_acc: 0.9810\n",
      "Epoch 61/150\n",
      "426/426 [==============================] - 0s 331us/step - loss: 30321.7539 - acc: 0.9648 - val_loss: 28675.9767 - val_acc: 0.9810\n",
      "Epoch 62/150\n",
      "426/426 [==============================] - 0s 366us/step - loss: 29930.2073 - acc: 0.9648 - val_loss: 28306.4163 - val_acc: 0.9810\n",
      "Epoch 63/150\n",
      "426/426 [==============================] - 0s 350us/step - loss: 29542.2202 - acc: 0.9648 - val_loss: 27950.4165 - val_acc: 0.9810\n",
      "Epoch 64/150\n",
      "426/426 [==============================] - 0s 334us/step - loss: 29165.6913 - acc: 0.9648 - val_loss: 27597.1464 - val_acc: 0.9810\n",
      "Epoch 65/150\n",
      "426/426 [==============================] - 0s 431us/step - loss: 28787.3675 - acc: 0.9648 - val_loss: 27239.2906 - val_acc: 0.9810\n",
      "Epoch 66/150\n",
      "426/426 [==============================] - 0s 300us/step - loss: 28412.9902 - acc: 0.9648 - val_loss: 26894.2977 - val_acc: 0.9810\n",
      "Epoch 67/150\n",
      "426/426 [==============================] - 0s 298us/step - loss: 28046.1633 - acc: 0.9648 - val_loss: 26549.4971 - val_acc: 0.9810\n",
      "Epoch 68/150\n",
      "426/426 [==============================] - 0s 450us/step - loss: 27682.3396 - acc: 0.9648 - val_loss: 26207.3454 - val_acc: 0.9810\n",
      "Epoch 69/150\n",
      "426/426 [==============================] - 0s 372us/step - loss: 27318.1642 - acc: 0.9648 - val_loss: 25865.6914 - val_acc: 0.9810\n",
      "Epoch 70/150\n",
      "426/426 [==============================] - 0s 282us/step - loss: 26958.2005 - acc: 0.9648 - val_loss: 25532.2388 - val_acc: 0.9810\n",
      "Epoch 71/150\n",
      "426/426 [==============================] - 0s 389us/step - loss: 26608.2775 - acc: 0.9648 - val_loss: 25204.9689 - val_acc: 0.9810\n",
      "Epoch 72/150\n",
      "426/426 [==============================] - 0s 358us/step - loss: 26258.9217 - acc: 0.9648 - val_loss: 24877.0654 - val_acc: 0.9810\n",
      "Epoch 73/150\n",
      "426/426 [==============================] - 0s 348us/step - loss: 25914.2920 - acc: 0.9648 - val_loss: 24558.6783 - val_acc: 0.9810\n",
      "Epoch 74/150\n",
      "426/426 [==============================] - 0s 347us/step - loss: 25578.1917 - acc: 0.9648 - val_loss: 24243.5350 - val_acc: 0.9810\n",
      "Epoch 75/150\n",
      "426/426 [==============================] - 0s 274us/step - loss: 25243.9543 - acc: 0.9648 - val_loss: 23927.9133 - val_acc: 0.9810\n",
      "Epoch 76/150\n",
      "426/426 [==============================] - 0s 415us/step - loss: 24908.1592 - acc: 0.9648 - val_loss: 23610.9254 - val_acc: 0.9810\n",
      "Epoch 77/150\n",
      "426/426 [==============================] - 0s 426us/step - loss: 24577.0778 - acc: 0.9648 - val_loss: 23308.2591 - val_acc: 0.9810\n",
      "Epoch 78/150\n",
      "426/426 [==============================] - 0s 427us/step - loss: 24252.4123 - acc: 0.9648 - val_loss: 22999.6518 - val_acc: 0.9810\n",
      "Epoch 79/150\n",
      "426/426 [==============================] - 0s 339us/step - loss: 23932.6091 - acc: 0.9648 - val_loss: 22707.4819 - val_acc: 0.9810\n",
      "Epoch 80/150\n",
      "426/426 [==============================] - 0s 330us/step - loss: 23619.9750 - acc: 0.9648 - val_loss: 22411.0347 - val_acc: 0.9810\n",
      "Epoch 81/150\n",
      "426/426 [==============================] - 0s 307us/step - loss: 23308.0661 - acc: 0.9648 - val_loss: 22121.5743 - val_acc: 0.9810\n",
      "Epoch 82/150\n",
      "426/426 [==============================] - 0s 359us/step - loss: 23004.7599 - acc: 0.9648 - val_loss: 21837.9696 - val_acc: 0.9810\n",
      "Epoch 83/150\n",
      "426/426 [==============================] - 0s 359us/step - loss: 22700.6571 - acc: 0.9648 - val_loss: 21551.4263 - val_acc: 0.9810\n",
      "Epoch 84/150\n",
      "426/426 [==============================] - 0s 397us/step - loss: 22401.8937 - acc: 0.9648 - val_loss: 21274.6639 - val_acc: 0.9810\n",
      "Epoch 85/150\n",
      "426/426 [==============================] - 0s 425us/step - loss: 22108.6308 - acc: 0.9648 - val_loss: 21000.9695 - val_acc: 0.9810\n",
      "Epoch 86/150\n",
      "426/426 [==============================] - 0s 383us/step - loss: 21818.8306 - acc: 0.9648 - val_loss: 20734.5100 - val_acc: 0.9810\n",
      "Epoch 87/150\n",
      "426/426 [==============================] - 0s 362us/step - loss: 21536.5106 - acc: 0.9648 - val_loss: 20467.4845 - val_acc: 0.9810\n",
      "Epoch 88/150\n",
      "426/426 [==============================] - 0s 284us/step - loss: 21254.6925 - acc: 0.9648 - val_loss: 20205.1247 - val_acc: 0.9810\n",
      "Epoch 89/150\n",
      "426/426 [==============================] - 0s 410us/step - loss: 20978.2037 - acc: 0.9648 - val_loss: 19947.8629 - val_acc: 0.9810\n",
      "Epoch 90/150\n",
      "426/426 [==============================] - 0s 425us/step - loss: 20706.1234 - acc: 0.9648 - val_loss: 19694.5608 - val_acc: 0.9810\n",
      "Epoch 91/150\n",
      "426/426 [==============================] - 0s 402us/step - loss: 20436.3419 - acc: 0.9648 - val_loss: 19442.2853 - val_acc: 0.9810\n",
      "Epoch 92/150\n",
      "426/426 [==============================] - 0s 449us/step - loss: 20172.3284 - acc: 0.9648 - val_loss: 19195.5609 - val_acc: 0.9810\n",
      "Epoch 93/150\n",
      "426/426 [==============================] - 0s 383us/step - loss: 19912.7832 - acc: 0.9648 - val_loss: 18957.7923 - val_acc: 0.9810\n",
      "Epoch 94/150\n",
      "426/426 [==============================] - 0s 592us/step - loss: 19659.4550 - acc: 0.9648 - val_loss: 18716.4708 - val_acc: 0.9810\n",
      "Epoch 95/150\n",
      "426/426 [==============================] - 0s 468us/step - loss: 19407.3135 - acc: 0.9648 - val_loss: 18483.4085 - val_acc: 0.9810\n",
      "Epoch 96/150\n",
      "426/426 [==============================] - 0s 382us/step - loss: 19159.5798 - acc: 0.9648 - val_loss: 18250.3702 - val_acc: 0.9810\n",
      "Epoch 97/150\n",
      "426/426 [==============================] - 0s 418us/step - loss: 18914.2861 - acc: 0.9648 - val_loss: 18022.6747 - val_acc: 0.9810\n",
      "Epoch 98/150\n",
      "426/426 [==============================] - 0s 310us/step - loss: 18674.5061 - acc: 0.9648 - val_loss: 17798.0473 - val_acc: 0.9810\n",
      "Epoch 99/150\n",
      "426/426 [==============================] - 0s 424us/step - loss: 18438.7582 - acc: 0.9648 - val_loss: 17583.4078 - val_acc: 0.9810\n",
      "Epoch 100/150\n",
      "426/426 [==============================] - 0s 283us/step - loss: 18210.5202 - acc: 0.9648 - val_loss: 17369.1192 - val_acc: 0.9810\n",
      "Epoch 101/150\n",
      "426/426 [==============================] - 0s 407us/step - loss: 17982.1106 - acc: 0.9648 - val_loss: 17154.3600 - val_acc: 0.9810\n",
      "Epoch 102/150\n",
      "426/426 [==============================] - 0s 411us/step - loss: 17758.2164 - acc: 0.9648 - val_loss: 16947.1349 - val_acc: 0.9810\n",
      "Epoch 103/150\n",
      "426/426 [==============================] - 0s 447us/step - loss: 17537.5122 - acc: 0.9648 - val_loss: 16737.7958 - val_acc: 0.9810\n",
      "Epoch 104/150\n",
      "426/426 [==============================] - 0s 391us/step - loss: 17322.3044 - acc: 0.9648 - val_loss: 16545.7942 - val_acc: 0.9810\n",
      "Epoch 105/150\n",
      "426/426 [==============================] - 0s 385us/step - loss: 17114.7028 - acc: 0.9648 - val_loss: 16347.0330 - val_acc: 0.9810\n",
      "Epoch 106/150\n",
      "426/426 [==============================] - 0s 429us/step - loss: 16907.1786 - acc: 0.9648 - val_loss: 16157.4164 - val_acc: 0.9810\n",
      "Epoch 107/150\n",
      "426/426 [==============================] - 0s 476us/step - loss: 16706.6085 - acc: 0.9648 - val_loss: 15971.4299 - val_acc: 0.9810\n",
      "Epoch 108/150\n",
      "426/426 [==============================] - 0s 429us/step - loss: 16507.9893 - acc: 0.9648 - val_loss: 15783.3874 - val_acc: 0.9810\n",
      "Epoch 109/150\n",
      "426/426 [==============================] - 0s 402us/step - loss: 16310.6925 - acc: 0.9648 - val_loss: 15599.8083 - val_acc: 0.9810\n",
      "Epoch 110/150\n",
      "426/426 [==============================] - 0s 435us/step - loss: 16116.8742 - acc: 0.9648 - val_loss: 15419.1067 - val_acc: 0.9810\n",
      "Epoch 111/150\n",
      "426/426 [==============================] - 0s 370us/step - loss: 15928.1791 - acc: 0.9648 - val_loss: 15244.2750 - val_acc: 0.9810\n",
      "Epoch 112/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 15864.1369 - acc: 0.968 - 0s 456us/step - loss: 15742.9165 - acc: 0.9648 - val_loss: 15071.7932 - val_acc: 0.9810\n",
      "Epoch 113/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "426/426 [==============================] - 0s 460us/step - loss: 15560.9977 - acc: 0.9648 - val_loss: 14902.4791 - val_acc: 0.9810\n",
      "Epoch 114/150\n",
      "426/426 [==============================] - 0s 368us/step - loss: 15382.9414 - acc: 0.9648 - val_loss: 14738.9664 - val_acc: 0.9810\n",
      "Epoch 115/150\n",
      "426/426 [==============================] - 0s 296us/step - loss: 15209.0214 - acc: 0.9648 - val_loss: 14576.4203 - val_acc: 0.9810\n",
      "Epoch 116/150\n",
      "426/426 [==============================] - 0s 563us/step - loss: 15038.6936 - acc: 0.9648 - val_loss: 14417.5640 - val_acc: 0.9810\n",
      "Epoch 117/150\n",
      "426/426 [==============================] - 0s 516us/step - loss: 14870.1332 - acc: 0.9648 - val_loss: 14260.3627 - val_acc: 0.9810\n",
      "Epoch 118/150\n",
      "426/426 [==============================] - 0s 354us/step - loss: 14706.2033 - acc: 0.9648 - val_loss: 14108.8520 - val_acc: 0.9810\n",
      "Epoch 119/150\n",
      "426/426 [==============================] - 0s 435us/step - loss: 14545.7077 - acc: 0.9648 - val_loss: 13960.4649 - val_acc: 0.9810\n",
      "Epoch 120/150\n",
      "426/426 [==============================] - 0s 432us/step - loss: 14388.6618 - acc: 0.9648 - val_loss: 13812.7641 - val_acc: 0.9810\n",
      "Epoch 121/150\n",
      "426/426 [==============================] - 0s 353us/step - loss: 14234.5827 - acc: 0.9648 - val_loss: 13672.2696 - val_acc: 0.9810\n",
      "Epoch 122/150\n",
      "426/426 [==============================] - 0s 391us/step - loss: 14084.1170 - acc: 0.9648 - val_loss: 13531.0851 - val_acc: 0.9810\n",
      "Epoch 123/150\n",
      "426/426 [==============================] - 0s 307us/step - loss: 13935.2109 - acc: 0.9648 - val_loss: 13394.1431 - val_acc: 0.9810\n",
      "Epoch 124/150\n",
      "426/426 [==============================] - 0s 299us/step - loss: 13791.7163 - acc: 0.9648 - val_loss: 13258.7567 - val_acc: 0.9810\n",
      "Epoch 125/150\n",
      "426/426 [==============================] - 0s 369us/step - loss: 13651.4913 - acc: 0.9648 - val_loss: 13132.0086 - val_acc: 0.9810\n",
      "Epoch 126/150\n",
      "426/426 [==============================] - 0s 370us/step - loss: 13514.5942 - acc: 0.9648 - val_loss: 13003.4596 - val_acc: 0.9810\n",
      "Epoch 127/150\n",
      "426/426 [==============================] - 0s 328us/step - loss: 13378.6098 - acc: 0.9648 - val_loss: 12877.1919 - val_acc: 0.9810\n",
      "Epoch 128/150\n",
      "426/426 [==============================] - 0s 455us/step - loss: 13246.3821 - acc: 0.9648 - val_loss: 12756.0537 - val_acc: 0.9810\n",
      "Epoch 129/150\n",
      "426/426 [==============================] - 0s 469us/step - loss: 13119.6879 - acc: 0.9648 - val_loss: 12637.9479 - val_acc: 0.9810\n",
      "Epoch 130/150\n",
      "426/426 [==============================] - 0s 375us/step - loss: 12992.7761 - acc: 0.9648 - val_loss: 12518.4735 - val_acc: 0.9810\n",
      "Epoch 131/150\n",
      "426/426 [==============================] - 0s 321us/step - loss: 12867.6815 - acc: 0.9648 - val_loss: 12403.7885 - val_acc: 0.9810\n",
      "Epoch 132/150\n",
      "426/426 [==============================] - 0s 315us/step - loss: 12746.8851 - acc: 0.9648 - val_loss: 12292.3422 - val_acc: 0.9810\n",
      "Epoch 133/150\n",
      "426/426 [==============================] - 0s 313us/step - loss: 12628.5912 - acc: 0.9648 - val_loss: 12181.1871 - val_acc: 0.9810\n",
      "Epoch 134/150\n",
      "426/426 [==============================] - 0s 491us/step - loss: 12512.9563 - acc: 0.9648 - val_loss: 12075.3968 - val_acc: 0.9810\n",
      "Epoch 135/150\n",
      "426/426 [==============================] - 0s 403us/step - loss: 12400.4717 - acc: 0.9648 - val_loss: 11969.9720 - val_acc: 0.9810\n",
      "Epoch 136/150\n",
      "426/426 [==============================] - 0s 301us/step - loss: 12290.9383 - acc: 0.9648 - val_loss: 11872.1971 - val_acc: 0.9810\n",
      "Epoch 137/150\n",
      "426/426 [==============================] - 0s 398us/step - loss: 12185.8257 - acc: 0.9648 - val_loss: 11772.7502 - val_acc: 0.9810\n",
      "Epoch 138/150\n",
      "426/426 [==============================] - 0s 390us/step - loss: 12080.8932 - acc: 0.9648 - val_loss: 11674.9668 - val_acc: 0.9810\n",
      "Epoch 139/150\n",
      "426/426 [==============================] - 0s 386us/step - loss: 11976.9218 - acc: 0.9648 - val_loss: 11577.4316 - val_acc: 0.9810\n",
      "Epoch 140/150\n",
      "426/426 [==============================] - 0s 319us/step - loss: 11876.2918 - acc: 0.9648 - val_loss: 11486.4814 - val_acc: 0.9810\n",
      "Epoch 141/150\n",
      "426/426 [==============================] - 0s 291us/step - loss: 11779.0734 - acc: 0.9648 - val_loss: 11396.3398 - val_acc: 0.9810\n",
      "Epoch 142/150\n",
      "426/426 [==============================] - 0s 402us/step - loss: 11683.1960 - acc: 0.9648 - val_loss: 11308.6793 - val_acc: 0.9810\n",
      "Epoch 143/150\n",
      "426/426 [==============================] - 0s 402us/step - loss: 11591.3832 - acc: 0.9648 - val_loss: 11222.8720 - val_acc: 0.9810\n",
      "Epoch 144/150\n",
      "426/426 [==============================] - 0s 407us/step - loss: 11500.7763 - acc: 0.9648 - val_loss: 11138.8477 - val_acc: 0.9810\n",
      "Epoch 145/150\n",
      "426/426 [==============================] - 0s 341us/step - loss: 11412.0875 - acc: 0.9648 - val_loss: 11057.0077 - val_acc: 0.9810\n",
      "Epoch 146/150\n",
      "426/426 [==============================] - 0s 346us/step - loss: 11326.0013 - acc: 0.9648 - val_loss: 10978.3923 - val_acc: 0.9810\n",
      "Epoch 147/150\n",
      "426/426 [==============================] - 0s 368us/step - loss: 11242.3763 - acc: 0.9648 - val_loss: 10899.6917 - val_acc: 0.9810\n",
      "Epoch 148/150\n",
      "426/426 [==============================] - 0s 458us/step - loss: 11159.4118 - acc: 0.9648 - val_loss: 10824.0616 - val_acc: 0.9810\n",
      "Epoch 149/150\n",
      "426/426 [==============================] - 0s 453us/step - loss: 11079.5430 - acc: 0.9648 - val_loss: 10750.1236 - val_acc: 0.9810\n",
      "Epoch 150/150\n",
      "426/426 [==============================] - 0s 387us/step - loss: 11001.7118 - acc: 0.9648 - val_loss: 10678.2432 - val_acc: 0.9810\n"
     ]
    }
   ],
   "source": [
    "from keras.optimizers import RMSprop,Adam\n",
    "\n",
    "\n",
    "model.add(Dense(64, activation='relu', input_shape=(12,)))\n",
    "model.add(Dense(8, activation='relu', input_shape=(16,)))\n",
    "model.add(Dense(12, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=RMSprop(),\n",
    "              metrics=['accuracy'])\n",
    "history = model.fit(X_train, y_train,\n",
    "                    epochs=150,batch_size=32,\n",
    "                    verbose=1,\n",
    "                    validation_data=(X_test, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 98.10%\n"
     ]
    }
   ],
   "source": [
    "# evaluate the model\n",
    "scores = model.evaluate(X_test,y_test, verbose=0)\n",
    "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "model.save(\"solar_model.h5\")\n",
    "m = load_model(\"solar_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "637/637 [==============================] - 0s 77us/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = m.predict_classes(X,verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "637/637 [==============================] - 0s 687us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11,\n",
       "       11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11,\n",
       "       11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11,\n",
       "       11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11,\n",
       "       11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11,\n",
       "       11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11,\n",
       "       11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11,\n",
       "       11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11,\n",
       "       11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11,\n",
       "       11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11,\n",
       "       11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11,\n",
       "       11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11,\n",
       "       11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11,\n",
       "       11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11,\n",
       "       11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11,\n",
       "       11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11,\n",
       "       11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11,\n",
       "       11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11,\n",
       "       11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11,\n",
       "       11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11,\n",
       "       11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11,\n",
       "       11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11,\n",
       "       11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11,\n",
       "       11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11,\n",
       "       11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11,\n",
       "       11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11,\n",
       "       11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11,\n",
       "       11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11,\n",
       "       11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11,\n",
       "       11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11,\n",
       "       11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11,\n",
       "       11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11,\n",
       "       11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11,\n",
       "       11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11,\n",
       "       11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11,\n",
       "       11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11,\n",
       "       11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11,\n",
       "       11, 11, 11, 11, 11, 11, 11, 11])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model.predict_classes(X,verbose=1)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import argparse\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the outputs folder - save any outputs you want managed by AzureML here\n",
    "os.makedirs('./outputs', exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
